{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97a2e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from mlxtend.classifier  import EnsembleVoteClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8034a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>semicol</th>\n",
       "      <th>paren</th>\n",
       "      <th>bracket</th>\n",
       "      <th>bang</th>\n",
       "      <th>dollar</th>\n",
       "      <th>pound</th>\n",
       "      <th>cap_avg</th>\n",
       "      <th>cap_long</th>\n",
       "      <th>cap_total</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.510</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.718</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.426</td>\n",
       "      <td>72</td>\n",
       "      <td>819</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.428</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.857</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.812</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.687</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.138</td>\n",
       "      <td>149</td>\n",
       "      <td>1235</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      make  address   all   3d   our  over  remove  internet  order  mail  \\\n",
       "0     0.00     0.00  0.29  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "1     0.46     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "2     0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "3     0.33     0.44  0.37  0.0  0.14  0.11    0.00      0.07   0.97  1.16   \n",
       "4     0.00     2.08  0.00  0.0  3.12  0.00    1.04      0.00   0.00  0.00   \n",
       "...    ...      ...   ...  ...   ...   ...     ...       ...    ...   ...   \n",
       "4596  0.00     0.00  0.53  0.0  0.00  0.53    0.00      0.00   0.00  0.53   \n",
       "4597  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "4598  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "4599  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00   \n",
       "4600  0.13     0.26  0.52  0.0  0.26  0.00    0.13      0.00   0.00  0.39   \n",
       "\n",
       "      ...  semicol  paren  bracket   bang  dollar  pound  cap_avg  cap_long  \\\n",
       "0     ...    0.000  0.178      0.0  0.044   0.000   0.00    1.666        10   \n",
       "1     ...    0.000  0.125      0.0  0.000   0.000   0.00    1.510        10   \n",
       "2     ...    0.000  0.000      0.0  0.000   0.000   0.00    1.718        11   \n",
       "3     ...    0.006  0.159      0.0  0.069   0.221   0.11    3.426        72   \n",
       "4     ...    0.000  0.000      0.0  0.263   0.000   0.00    1.428         4   \n",
       "...   ...      ...    ...      ...    ...     ...    ...      ...       ...   \n",
       "4596  ...    0.000  0.101      0.0  0.000   0.000   0.00    1.857        16   \n",
       "4597  ...    0.000  0.443      0.0  0.221   0.665   0.00    3.812        15   \n",
       "4598  ...    0.000  0.000      0.0  0.000   0.000   0.00    1.000         1   \n",
       "4599  ...    0.000  0.218      0.0  0.218   0.000   0.00    1.687        10   \n",
       "4600  ...    0.000  0.000      0.0  0.366   0.000   0.04    7.138       149   \n",
       "\n",
       "      cap_total  Class  \n",
       "0           180    ham  \n",
       "1            74    ham  \n",
       "2            55    ham  \n",
       "3           819   spam  \n",
       "4            20   spam  \n",
       "...         ...    ...  \n",
       "4596         52    ham  \n",
       "4597         61   spam  \n",
       "4598          3    ham  \n",
       "4599         27    ham  \n",
       "4600       1235   spam  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the data from the local system\n",
    "df=pd.read_excel(r\"/Users/arjunsahas/Downloads/spam.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1346b8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0197b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   make        4601 non-null   float64\n",
      " 1   address     4601 non-null   float64\n",
      " 2   all         4601 non-null   float64\n",
      " 3   3d          4601 non-null   float64\n",
      " 4   our         4601 non-null   float64\n",
      " 5   over        4601 non-null   float64\n",
      " 6   remove      4601 non-null   float64\n",
      " 7   internet    4601 non-null   float64\n",
      " 8   order       4601 non-null   float64\n",
      " 9   mail        4601 non-null   float64\n",
      " 10  receive     4601 non-null   float64\n",
      " 11  will        4601 non-null   float64\n",
      " 12  people      4601 non-null   float64\n",
      " 13  report      4601 non-null   float64\n",
      " 14  addresses   4601 non-null   float64\n",
      " 15  free        4601 non-null   float64\n",
      " 16  business    4601 non-null   float64\n",
      " 17  email       4601 non-null   float64\n",
      " 18  you         4601 non-null   float64\n",
      " 19  credit      4601 non-null   float64\n",
      " 20  your        4601 non-null   float64\n",
      " 21  font        4601 non-null   float64\n",
      " 22  0           4601 non-null   float64\n",
      " 23  money       4601 non-null   float64\n",
      " 24  hp          4601 non-null   float64\n",
      " 25  hpl         4601 non-null   float64\n",
      " 26  george      4601 non-null   float64\n",
      " 27  650         4601 non-null   float64\n",
      " 28  lab         4601 non-null   float64\n",
      " 29  labs        4601 non-null   float64\n",
      " 30  telnet      4601 non-null   float64\n",
      " 31  857         4601 non-null   float64\n",
      " 32  data        4601 non-null   float64\n",
      " 33  415         4601 non-null   float64\n",
      " 34  85          4601 non-null   float64\n",
      " 35  technology  4601 non-null   float64\n",
      " 36  1999        4601 non-null   float64\n",
      " 37  parts       4601 non-null   float64\n",
      " 38  pm          4601 non-null   float64\n",
      " 39  direct      4601 non-null   float64\n",
      " 40  cs          4601 non-null   float64\n",
      " 41  meeting     4601 non-null   float64\n",
      " 42  original    4601 non-null   float64\n",
      " 43  project     4601 non-null   float64\n",
      " 44  re          4601 non-null   float64\n",
      " 45  edu         4601 non-null   float64\n",
      " 46  table       4601 non-null   float64\n",
      " 47  conference  4601 non-null   float64\n",
      " 48  semicol     4601 non-null   float64\n",
      " 49  paren       4601 non-null   float64\n",
      " 50  bracket     4601 non-null   float64\n",
      " 51  bang        4601 non-null   float64\n",
      " 52  dollar      4601 non-null   float64\n",
      " 53  pound       4601 non-null   float64\n",
      " 54  cap_avg     4601 non-null   float64\n",
      " 55  cap_long    4601 non-null   int64  \n",
      " 56  cap_total   4601 non-null   int64  \n",
      " 57  Class       4601 non-null   object \n",
      "dtypes: float64(55), int64(2), object(1)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f89286f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(df[\"Class\"],hue=df[\"Class\"])\n",
    "plt.title(\"Number of ham and spam email in the dataset\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55fb8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the target column to ham as 0 and spam as 1.\n",
    "df['Class']=df[\"Class\"].replace({\"ham\":0,\"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fed3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dependent and Independent features\n",
    "X=df.drop(columns=['Class'],axis=1)\n",
    "y=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "971de1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into trainingset and testingset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0930f",
   "metadata": {},
   "source": [
    "### Fused models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e5542f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=DecisionTreeClassifier()\n",
    "clf2=GaussianNB()\n",
    "clf3=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "508eb837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fused model 0.9341057204923968\n"
     ]
    }
   ],
   "source": [
    "model=EnsembleVoteClassifier(clfs=[clf1,clf2,clf3],voting=\"hard\")\n",
    "model.fit(X_train,y_train)\n",
    "pred_1=model.predict(X_test)\n",
    "print(\"Accuracy of Fused model\",accuracy_score(y_test,pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98316f6",
   "metadata": {},
   "source": [
    "### Adaboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9f736144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost model accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "#adaboost model by default it use Decisiontree as base learner.\n",
    "ada_model=AdaBoostClassifier()\n",
    "#training the model\n",
    "ada_model.fit(X_test,y_test)\n",
    "#prediction\n",
    "pred_4=ada_model.predict(X_test)\n",
    "acc_score_ada=accuracy_score(y_test,pred_4)\n",
    "print(\"AdaBoost model accuracy %.2f\" % acc_score_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b385395b",
   "metadata": {},
   "source": [
    "### RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8588827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest model accuracy 0.95\n"
     ]
    }
   ],
   "source": [
    "rf_model=RandomForestClassifier(n_estimators=1000)\n",
    "rf_model.fit(X_train,y_train)\n",
    "pred_5=rf_model.predict(X_test)\n",
    "acc_score_rf=accuracy_score(y_test,pred_5)\n",
    "print(\"RandomForest model accuracy %.2f\" % acc_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c5ac7",
   "metadata": {},
   "source": [
    "### 50% - 50% split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5be6db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing 50-50\n",
    "X_train_1,X_test_1,y_train_1,y_test_1=train_test_split(X,y,test_size=0.5,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e876b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fused model model with 50-50 split 0.9322033898305084\n",
      "accuracy score of AdaBoost model with 50-50 split : 0.94\n"
     ]
    }
   ],
   "source": [
    "fused_1=EnsembleVoteClassifier(clfs=[clf1,clf2,clf3],voting=\"hard\")\n",
    "fused_1.fit(X_train_1,y_train_1)\n",
    "fused_pred_1=fused_1.predict(X_test_1)\n",
    "print(\"Accuracy of Fused model model with 50-50 split\",accuracy_score(y_test_1,fused_pred_1))\n",
    "\n",
    "ada_1=AdaBoostClassifier()\n",
    "ada_1.fit(X_train_1,y_train_1)\n",
    "fused_pred_ada=ada_1.predict(X_test_1)\n",
    "print(\"accuracy score of AdaBoost model with 50-50 split : {:.2f}\".format(accuracy_score(y_test_1,fused_pred_ada)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6d2f5",
   "metadata": {},
   "source": [
    "### 60% - 40% Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0e6a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing 60-40\n",
    "X_train_2,X_test_2,y_train_2,y_test_2=train_test_split(X,y,test_size=0.4,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3625b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fused model with 60-40 split 0.9369907658881043\n",
      "accuracy score of AdaBoost model with 60-40 split : 0.94\n"
     ]
    }
   ],
   "source": [
    "fused_2=EnsembleVoteClassifier(clfs=[clf1,clf2,clf3],voting=\"hard\")\n",
    "fused_2.fit(X_train_2,y_train_2)\n",
    "fused_pred_2=fused_2.predict(X_test_2)\n",
    "print(\"Accuracy of Fused model with 60-40 split\",accuracy_score(y_test_2,fused_pred_2))\n",
    "\n",
    "ada_2=AdaBoostClassifier()\n",
    "ada_2.fit(X_train_2,y_train_2)\n",
    "fused_pred_ada_2=ada_2.predict(X_test_2)\n",
    "print(\"accuracy score of AdaBoost model with 60-40 split : {:.2f}\".format(accuracy_score(y_test_2,fused_pred_ada_2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3ac2c",
   "metadata": {},
   "source": [
    "### 70% - 30% Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80f56aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing 70-30\n",
    "X_train_3,X_test_3,y_train_3,y_test_3=train_test_split(X,y,test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fd5d314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fused model with 70-30 split 0.9355539464156408\n",
      "accuracy score of AdaBoost model with 70-30 split : 0.94\n"
     ]
    }
   ],
   "source": [
    "fused_3=EnsembleVoteClassifier(clfs=[clf1,clf2,clf3],voting=\"hard\")\n",
    "fused_3.fit(X_train_3,y_train_3)\n",
    "fused_pred_3=fused_3.predict(X_test_3)\n",
    "print(\"Accuracy of Fused model with 70-30 split\",accuracy_score(y_test_3,fused_pred_3))\n",
    "\n",
    "ada_3=AdaBoostClassifier()\n",
    "ada_3.fit(X_train_3,y_train_3)\n",
    "fused_pred_ada_3=ada_3.predict(X_test_3)\n",
    "print(\"accuracy score of AdaBoost model with 70-30 split : {:.2f}\".format(accuracy_score(y_test_3,fused_pred_ada_3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3010eb",
   "metadata": {},
   "source": [
    "### 80% - 20% Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "641c7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing 80-20\n",
    "X_train_4,X_test_4,y_train_4,y_test_4=train_test_split(X,y,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "999c9077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fused model with 80-20 split 0.9402823018458197\n",
      "accuracy score of AdaBoost model with 80-20 split : 0.94\n"
     ]
    }
   ],
   "source": [
    "fused_4=EnsembleVoteClassifier(clfs=[clf1,clf2,clf3],voting=\"hard\")\n",
    "fused_4.fit(X_train_4,y_train_4)\n",
    "fused_pred_4=fused_4.predict(X_test_4)\n",
    "print(\"Accuracy of Fused model with 80-20 split\",accuracy_score(y_test_4,fused_pred_4))\n",
    "\n",
    "ada_4=AdaBoostClassifier()\n",
    "ada_4.fit(X_train_4,y_train_4)\n",
    "fused_pred_ada_4=ada_4.predict(X_test_4)\n",
    "print(\"accuracy score of AdaBoost model with 80-20 split : {:.2f}\".format(accuracy_score(y_test_4,fused_pred_ada_4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31847ffb",
   "metadata": {},
   "source": [
    "### Accuracies of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3201f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier() accuracy is 0.915\n",
      "confusion matrix of DecisionTreeClassifier() \n",
      " [[801  73]\n",
      " [ 45 462]]\n",
      "classification report of DecisionTreeClassifier() \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       874\n",
      "           1       0.86      0.91      0.89       507\n",
      "\n",
      "    accuracy                           0.91      1381\n",
      "   macro avg       0.91      0.91      0.91      1381\n",
      "weighted avg       0.92      0.91      0.92      1381\n",
      "\n",
      "per-class classification accuracy of spam: 0.91\n",
      "per-class classification accuracy of ham: 0.92\n",
      "======================================================================================================\n",
      "GaussianNB() accuracy is 0.810\n",
      "confusion matrix of GaussianNB() \n",
      " [[634 240]\n",
      " [ 22 485]]\n",
      "classification report of GaussianNB() \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83       874\n",
      "           1       0.67      0.96      0.79       507\n",
      "\n",
      "    accuracy                           0.81      1381\n",
      "   macro avg       0.82      0.84      0.81      1381\n",
      "weighted avg       0.86      0.81      0.81      1381\n",
      "\n",
      "per-class classification accuracy of spam: 0.96\n",
      "per-class classification accuracy of ham: 0.73\n",
      "======================================================================================================\n",
      "LogisticRegression() accuracy is 0.925\n",
      "confusion matrix of LogisticRegression() \n",
      " [[832  42]\n",
      " [ 62 445]]\n",
      "classification report of LogisticRegression() \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       874\n",
      "           1       0.91      0.88      0.90       507\n",
      "\n",
      "    accuracy                           0.92      1381\n",
      "   macro avg       0.92      0.91      0.92      1381\n",
      "weighted avg       0.92      0.92      0.92      1381\n",
      "\n",
      "per-class classification accuracy of spam: 0.88\n",
      "per-class classification accuracy of ham: 0.95\n",
      "======================================================================================================\n",
      "AdaBoostClassifier() accuracy is 0.941\n",
      "confusion matrix of AdaBoostClassifier() \n",
      " [[836  38]\n",
      " [ 44 463]]\n",
      "classification report of AdaBoostClassifier() \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       874\n",
      "           1       0.92      0.91      0.92       507\n",
      "\n",
      "    accuracy                           0.94      1381\n",
      "   macro avg       0.94      0.93      0.94      1381\n",
      "weighted avg       0.94      0.94      0.94      1381\n",
      "\n",
      "per-class classification accuracy of spam: 0.91\n",
      "per-class classification accuracy of ham: 0.96\n",
      "======================================================================================================\n",
      "RandomForestClassifier() accuracy is 0.952\n",
      "confusion matrix of RandomForestClassifier() \n",
      " [[845  29]\n",
      " [ 37 470]]\n",
      "classification report of RandomForestClassifier() \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       874\n",
      "           1       0.94      0.93      0.93       507\n",
      "\n",
      "    accuracy                           0.95      1381\n",
      "   macro avg       0.95      0.95      0.95      1381\n",
      "weighted avg       0.95      0.95      0.95      1381\n",
      "\n",
      "per-class classification accuracy of spam: 0.93\n",
      "per-class classification accuracy of ham: 0.97\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "models=[DecisionTreeClassifier(),GaussianNB(),LogisticRegression(),AdaBoostClassifier(),RandomForestClassifier()]\n",
    "for i in models:\n",
    "    model=i\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    acc_score=accuracy_score(y_test,y_pred)\n",
    "    print(\"{} accuracy is {:.3f}\" .format(i,acc_score))\n",
    "    con_matrix=confusion_matrix(y_test,y_pred)\n",
    "    print(\"confusion matrix of {} \\n {}\".format(i,con_matrix))\n",
    "    cls_report=classification_report(y_test,y_pred)\n",
    "    print(\"classification report of {} \\n {}\".format(i,cls_report))\n",
    "    #perclass accuracy rate\n",
    "    tp=con_matrix[0][0]\n",
    "    fp=con_matrix[0][1]\n",
    "    fn=con_matrix[1][0]\n",
    "    tn=con_matrix[1][1]\n",
    "    #per-class classification accuracy\n",
    "    spam=tn/(fn+tn)\n",
    "    print(\"per-class classification accuracy of spam: {:.2f}\".format(spam))\n",
    "    ham=tp/(tp+fp)\n",
    "    print(\"per-class classification accuracy of ham: {:.2f}\".format(ham))\n",
    "    print(\"======================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65927fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
